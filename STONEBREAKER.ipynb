{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional, Dict, Annotated, List, Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AnyMessage, AIMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from Prompts import Prompts\n",
    "from LLMProvider import LLMProvider\n",
    "from PydanticModels import StoneBreakerState, IsContextEnough, FixContext, Query, OptimizedQuery, FinalEvaluation\n",
    "from ParquetRAG import ParquetRAG\n",
    "import sqlglot\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_provider=LLMProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_llm = llm_provider.get_llm()\n",
    "groq_is_context_enough = llm_provider.get_structured_llm(IsContextEnough)\n",
    "groq_fix_context = llm_provider.get_structured_llm(FixContext)\n",
    "groq_gen_query = llm_provider.get_structured_llm(Query)\n",
    "groq_optimized_query = llm_provider.get_structured_llm(OptimizedQuery)\n",
    "groq_final_evaluation = llm_provider.get_structured_llm(FinalEvaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_prompt_node(state: StoneBreakerState):\n",
    "    sql_prompt = input(\"Enter the SQL prompt you want: \")\n",
    "    return {   \n",
    "        \"sql_prompt\": sql_prompt\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def database_connection_node(state:StoneBreakerState):\n",
    "    db_path=input(\"Enter the path to your SQLite database:\")\n",
    "    \n",
    "    try:\n",
    "        conn= sqlite3.connect(db_path)\n",
    "        cursor=conn.cursor()\n",
    "        \n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        tables=cursor.fetchall()\n",
    "        schema=[]\n",
    "        for table in tables:\n",
    "            table_name=table[0]\n",
    "            cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "            columns=cursor.fetchall()\n",
    "            \n",
    "            create_stmt = f\"CREATE TABLE {table_name} (\"\n",
    "            cols=[]\n",
    "            for col in columns:\n",
    "                col_name=col[1]\n",
    "                col_type=col[2]\n",
    "                is_pk= \"PRIMARY KEY\" if col[5]==1 else \"\"\n",
    "                cols.append(f\"{col_name} {col_type} {is_pk}\".strip())\n",
    "                \n",
    "            create_stmt += \", \".join(cols) + \");\"\n",
    "            schema.append(create_stmt)\n",
    "        conn.close()\n",
    "        \n",
    "        return {\n",
    "            \"data_base\":db_path,\n",
    "            \"sql_context\": \"\\n\".join(schema)\n",
    "        }\n",
    "    except  Exception as e:\n",
    "        return {\n",
    "            \"error\": f\"Failed to connect to database: {str(e)}\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_node(state: StoneBreakerState):\n",
    "    sql_context = state.sql_context\n",
    "    sql_prompt = state.sql_prompt\n",
    "    prompt = Prompts.gen_fix_context().invoke({\"sql_context\": sql_context, \"sql_prompt\": sql_prompt})\n",
    "    response = groq_fix_context.invoke(prompt)\n",
    "    refined_sql_context = response.context\n",
    "    return {\n",
    "        \"sql_context\": refined_sql_context,\n",
    "        \"sql_prompt\": sql_prompt   \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_context_from_vector_store_node(state: StoneBreakerState):\n",
    "    query = f\"\"\"\n",
    "    SQL Context: {state.sql_prompt}\n",
    "    SQL Prompt: {state.sql_context}\n",
    "    \"\"\"\n",
    "    parquetRAG = ParquetRAG()\n",
    "    results = parquetRAG.retrieve(query)\n",
    "    sql_context_from_vector_store = \"\"\n",
    "    for d in results:\n",
    "        sql_context_from_vector_store += d.page_content\n",
    "    return {\n",
    "        \"sql_context_from_vector_store\": sql_context_from_vector_store\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_generation_node(state: StoneBreakerState):\n",
    "    sql_context = state.sql_context\n",
    "    sql_prompt = state.sql_prompt\n",
    "    sql_context_from_vector_store = state.sql_context_from_vector_store\n",
    "    prompt = Prompts.gen_query().invoke({\n",
    "        \"sql_context\": sql_context, \n",
    "        \"sql_prompt\": sql_prompt,\n",
    "        \"sql_context_from_vector_store\": sql_context_from_vector_store\n",
    "    })\n",
    "    response = groq_gen_query.invoke(prompt)\n",
    "    sql_query_generated = response.query\n",
    "    return {\n",
    "        \"sql_query_generated\": sql_query_generated\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizations_node(state: StoneBreakerState):\n",
    "    sql_context = state.sql_context\n",
    "    sql_query = state.sql_query_generated\n",
    "    prompt = Prompts.gen_optimized_query().invoke({\"sql_context\": sql_context, \"sql_query\": sql_query})\n",
    "    response = groq_optimized_query.invoke(prompt)\n",
    "    sql_query_optimized = response.query\n",
    "    return {\n",
    "        \"sql_query_optimized\": sql_query_optimized\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execution_node(state: StoneBreakerState):\n",
    "    optimized_query = state.sql_query_optimized\n",
    "    database = state.data_base\n",
    "    try:\n",
    "        conn = sqlite3.connect(database) \n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(optimized_query)\n",
    "        result = cursor.fetchall()\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        return {\n",
    "            \"executed_success\": True,\n",
    "            \"execution_results\": result\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"executed_success\": False,\n",
    "            \"error\": str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_evaluation_node(state: StoneBreakerState):\n",
    "    sql_context = state.sql_context\n",
    "    sql_prompt = state.sql_prompt\n",
    "    sql_query = state.sql_query_optimized\n",
    "    prompt = Prompts.gen_final_evaluation().invoke({\n",
    "        \"sql_prompt\": sql_prompt,\n",
    "        \"sql_context\": sql_context,\n",
    "        \"sql_query\": sql_query\n",
    "    })\n",
    "    response = groq_final_evaluation.invoke(prompt)\n",
    "    return {\n",
    "        \"final_evaluation\": response.evaluation  \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion_node(state: StoneBreakerState):\n",
    "    sql_query = state.sql_query_optimized\n",
    "    spark_sql = sqlglot.transpile(sql_query, write=\"spark\", read=\"sqlite\", pretty=True)[0]  \n",
    "    trino_sql = sqlglot.transpile(sql_query, write=\"trino\", read=\"sqlite\", pretty=True)[0]  \n",
    "    return {\n",
    "        \"trino_sql\": trino_sql,\n",
    "        \"spark_sql\": spark_sql\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_context_evaluation_edge(state: StoneBreakerState):\n",
    "    sql_context = state.sql_context\n",
    "    sql_prompt = state.sql_prompt\n",
    "    prompt = Prompts.gen_is_context_enough().invoke({\"sql_context\": sql_context, \"sql_prompt\": sql_prompt})\n",
    "    evaluation_response = groq_is_context_enough.invoke(prompt)\n",
    "    if evaluation_response.isEnough:\n",
    "        return \"sql_context_from_vector_store_node\"\n",
    "    else:\n",
    "        return \"evaluation_node\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def error_edge(state: StoneBreakerState):\n",
    "    if state.executed_success:\n",
    "        return \"final_evaluation_node\"\n",
    "    else:\n",
    "        return \"query_generation_node\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_creation_edge(state: StoneBreakerState):\n",
    "    evaluation = state.final_evaluation\n",
    "    \n",
    "    if not evaluation:  \n",
    "        return \"query_generation_node\"\n",
    "    else:\n",
    "        return \"conversion_node\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=StoneBreakerState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7fb834382350>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"sql_prompt_node\", sql_prompt_node)\n",
    "workflow.add_node(\"database_connection_node\",database_connection_node)\n",
    "workflow.add_node(\"evaluation_node\", evaluation_node)\n",
    "workflow.add_node(\"sql_context_from_vector_store_node\", sql_context_from_vector_store_node)\n",
    "workflow.add_node(\"query_generation_node\", query_generation_node)\n",
    "workflow.add_node(\"optimizations_node\", optimizations_node)\n",
    "workflow.add_node(\"execution_node\", execution_node)\n",
    "workflow.add_node(\"final_evaluation_node\", final_evaluation_node)\n",
    "workflow.add_node(\"conversion_node\", conversion_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7fb834382350>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(START, \"sql_prompt_node\")\n",
    "workflow.add_edge(\"sql_prompt_node\",\"database_connection_node\")\n",
    "workflow.add_conditional_edges(\"database_connection_node\",sql_context_evaluation_edge)\n",
    "workflow.add_conditional_edges(\"evaluation_node\", sql_context_evaluation_edge)\n",
    "\n",
    "workflow.add_edge(\"sql_context_from_vector_store_node\", \"query_generation_node\")\n",
    "workflow.add_edge(\"query_generation_node\", \"optimizations_node\")\n",
    "workflow.add_edge(\"optimizations_node\", \"execution_node\")\n",
    "workflow.add_conditional_edges(\"execution_node\", error_edge)\n",
    "workflow.add_conditional_edges(\"final_evaluation_node\", check_creation_edge)\n",
    "workflow.add_edge(\"conversion_node\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sql_prompt_node': StateNodeSpec(runnable=sql_prompt_node(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None, input=<class 'PydanticModels.StoneBreakerState'>, retry_policy=None, ends=()),\n",
       " 'database_connection_node': StateNodeSpec(runnable=database_connection_node(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None, input=<class 'PydanticModels.StoneBreakerState'>, retry_policy=None, ends=()),\n",
       " 'evaluation_node': StateNodeSpec(runnable=evaluation_node(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None, input=<class 'PydanticModels.StoneBreakerState'>, retry_policy=None, ends=()),\n",
       " 'sql_context_from_vector_store_node': StateNodeSpec(runnable=sql_context_from_vector_store_node(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None, input=<class 'PydanticModels.StoneBreakerState'>, retry_policy=None, ends=()),\n",
       " 'query_generation_node': StateNodeSpec(runnable=query_generation_node(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None, input=<class 'PydanticModels.StoneBreakerState'>, retry_policy=None, ends=()),\n",
       " 'optimizations_node': StateNodeSpec(runnable=optimizations_node(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None, input=<class 'PydanticModels.StoneBreakerState'>, retry_policy=None, ends=()),\n",
       " 'execution_node': StateNodeSpec(runnable=execution_node(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None, input=<class 'PydanticModels.StoneBreakerState'>, retry_policy=None, ends=()),\n",
       " 'final_evaluation_node': StateNodeSpec(runnable=final_evaluation_node(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None, input=<class 'PydanticModels.StoneBreakerState'>, retry_policy=None, ends=()),\n",
       " 'conversion_node': StateNodeSpec(runnable=conversion_node(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None, input=<class 'PydanticModels.StoneBreakerState'>, retry_policy=None, ends=())}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Install pygraphviz to draw graphs: `pip install pygraphviz`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/Edgerr/.venv/lib/python3.10/site-packages/langchain_core/runnables/graph_png.py:136\u001b[0m, in \u001b[0;36mPngDrawer.draw\u001b[0;34m(self, graph, output_path)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpygraphviz\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpgv\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pygraphviz'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, display\n\u001b[0;32m----> 3\u001b[0m display(Image(\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m~/Desktop/Edgerr/.venv/lib/python3.10/site-packages/langchain_core/runnables/graph.py:557\u001b[0m, in \u001b[0;36mGraph.draw_png\u001b[0;34m(self, output_file_path, fontname, labels)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_png\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PngDrawer\n\u001b[1;32m    546\u001b[0m default_node_labels \u001b[38;5;241m=\u001b[39m {node\u001b[38;5;241m.\u001b[39mid: node\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues()}\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPngDrawer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfontname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mLabelsDict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdefault_node_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnodes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43medges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43medges\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 557\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Edgerr/.venv/lib/python3.10/site-packages/langchain_core/runnables/graph_png.py:139\u001b[0m, in \u001b[0;36mPngDrawer.draw\u001b[0;34m(self, graph, output_path)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    138\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstall pygraphviz to draw graphs: `pip install pygraphviz`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# Create a directed graph\u001b[39;00m\n\u001b[1;32m    142\u001b[0m viz \u001b[38;5;241m=\u001b[39m pgv\u001b[38;5;241m.\u001b[39mAGraph(directed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, nodesep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, ranksep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: Install pygraphviz to draw graphs: `pip install pygraphviz`."
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harshal/Desktop/Edgerr/ParaquetRAG.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\",model_kwargs={\"token\":\"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\"})\n",
      "/home/harshal/Desktop/Edgerr/ParaquetRAG.py:16: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = self.retriever.get_relevant_documents(query)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    output = graph.invoke({\"sql_context\":\"Nice\"}, config)\n",
    "except Exception as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sql_context': \"CREATE TABLE salesperson (salesperson_id INT, name TEXT, region TEXT); INSERT INTO salesperson (salesperson_id, name, region) VALUES (1, 'John Doe', 'North'), (2, 'Jane Smith', 'South'); CREATE TABLE timber_sales (sales_id INT, salesperson_id INT, volume REAL, sale_date DATE); INSERT INTO timber_sales (sales_id, salesperson_id, volume, sale_date) VALUES (1, 1, 120, '2021-01-01'), (2, 1, 150, '2021-02-01'), (3, 2, 180, '2021-01-01');\",\n",
       " 'sql_prompt': 'What is the total volume of timber sold by each salesperson, sorted by salesperson?',\n",
       " 'sql_context_from_vector_store': \"SQL Context: CREATE TABLE salesperson (salesperson_id INT, name TEXT, region TEXT); INSERT INTO salesperson (salesperson_id, name, region) VALUES (1, 'John Doe', 'North'), (2, 'Jane Smith', 'South'); CREATE TABLE timber_sales (sales_id INT, salesperson_id INT, volume REAL, sale_date DATE); INSERT INTO timber_sales (sales_id, salesperson_id, volume, sale_date) VALUES (1, 1, 120, '2021-01-01'), (2, 1, 150, '2021-02-01'), (3, 2, 180, '2021-01-01');\\n        SQL Prompt: What is the total volume of timber sold by each salesperson, sorted by salesperson?\\n        SQL Query: SELECT salesperson_id, name, SUM(volume) as total_volume FROM timber_sales JOIN salesperson ON timber_sales.salesperson_id = salesperson.salesperson_id GROUP BY salesperson_id, name ORDER BY total_volume DESC;\\n        SQL Explanation: Joins timber_sales and salesperson tables, groups sales by salesperson, calculates total volume sold by each salesperson, and orders the results by total volume in descending order.SQL Context: CREATE TABLE salesperson (salesperson_id INT, name TEXT, region TEXT); INSERT INTO salesperson (salesperson_id, name, region) VALUES (1, 'John Doe', 'North'), (2, 'Jane Smith', 'South'); CREATE TABLE timber_sales (sales_id INT, salesperson_id INT, volume REAL, sale_date DATE); INSERT INTO timber_sales (sales_id, salesperson_id, volume, sale_date) VALUES (1, 1, 120, '2021-01-01'), (2, 1, 150, '2021-02-01'), (3, 2, 180, '2021-01-01');\\n        SQL Prompt: Which salesperson has sold the most timber in total?\\n        SQL Query: SELECT salesperson_id, SUM(volume) as total_volume FROM timber_sales JOIN salesperson ON timber_sales.salesperson_id = salesperson.salesperson_id GROUP BY salesperson_id ORDER BY total_volume DESC LIMIT 1;\\n        SQL Explanation: Joins timber_sales and salesperson tables, groups sales by salesperson, calculates total volume sold by each salesperson, and returns the salesperson with the highest volume.\\n        Domain: forestrySQL Context: CREATE TABLE salesperson (salesperson_id INT, name TEXT, region TEXT); INSERT INTO salesperson (salesperson_id, name, region) VALUES (1, 'John Doe', 'North'), (2, 'Jane Smith', 'South'); CREATE TABLE timber_sales (sales_id INT, salesperson_id INT, volume REAL, sale_date DATE); INSERT INTO timber_sales (sales_id, salesperson_id, volume, sale_date) VALUES (1, 1, 120, '2021-01-01'), (2, 1, 150, '2021-02-01'), (3, 2, 180, '2021-01-01');\\n        SQL Prompt: Find the total volume of timber sold in each region?\\n        SQL Query: SELECT region, SUM(volume) as total_volume FROM timber_sales ts JOIN salesperson s ON ts.salesperson_id = s.salesperson_id GROUP BY region;\\n        SQL Explanation: Joins timber_sales and salesperson tables, groups sales by region, calculates total volume sold in each region.\\n        Domain: forestry\\n        SQL Task Type: analytics and reporting\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
