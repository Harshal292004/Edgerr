{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional, Dict,Annotated\n",
    "from langgraph.graph import StateGraph ,START,END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langgraph.graph.message import  add_messages\n",
    "from pydantic import  BaseModel,Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY=\"LNDn2rbGUIGZznn1NXT7U4VcADf-d\"\n",
    "ENDPOINT=\"https://cloud.olakrutrim.com/v1\"\n",
    "MODEL_NAME=\"Llama-3.3-70B-Instruct\"\n",
    "\n",
    "llm = ChatOpenAI(api_key=API_KEY, base_url=ENDPOINT, model=MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buisness need \n",
    "Gather and Analyze business requirments \n",
    "Deffine scope and Granularity \n",
    "Identify Fact Tables and Their Measures \n",
    "Define Dimensions and Conformed Dimensions\n",
    "Design the Star Schema Structure\n",
    "Optimize for Performance and Scalability\n",
    "Validate, Test, and Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuisnessNeedPreProcessed(BaseModel):\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GranularityScope(BaseModel):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchemaDesign(BaseModel):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceOptimization(BaseModel):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErDiagram(BaseModel):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoddState(BaseModel):\n",
    "    business_need: Annotated[str, Field(description=\"Original raw business need text as provided by the client\")]\n",
    "    business_need_pre_processed: Annotated[str, Field(description=\"The pre-processed version of the business need with key points extracted\")]\n",
    "    granularity_scope: Annotated[str, Field(description=\"Defined granularity and scope of the business process for the schema\")]\n",
    "    schema_design: Annotated[str, Field(description=\"The designed star schema including fact and dimension definitions\")]\n",
    "    performance_optimization: Annotated[str, Field(description=\"Details on indexing, partitioning, and aggregation strategies to optimize performance\")]\n",
    "    er_diagram: Annotated[str, Field(description=\"Information about the generated ER diagram for the schema\")]\n",
    "    documentation: Annotated[str, Field(description=\"Documentation summarizing the design, decisions, and maintenance guidelines\")]\n",
    "    current_stage: Annotated[str, Field(description=\"Current processing stage in the Codd pipeline\")]\n",
    "    error: Annotated[str, Field(description=\"Defined granularity and scope of the business process for the schema\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages:Annotated[list,add_messages]\n",
    "\n",
    "\n",
    "graph_builder= StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47889/891791678.py:5: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(llm=llm, memory=memory)\n",
      "/tmp/ipykernel_47889/891791678.py:13: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = conversation.run(initial_prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM: To clarify your requirements, can you please tell me what specific data entities from the ERP and CRM systems you would like to integrate into the data warehouse? For example, are you looking to include customer information, sales orders, inventory levels, financial transactions, or something else? Additionally, what is the approximate volume of data we're talking about, and what is the desired frequency of data updates - real-time, daily, weekly, or monthly? \n",
      "\n",
      "Also, what type of reporting and decision-making are you trying to support with this data warehouse? Are you looking to create dashboards, generate ad-hoc reports, or perform advanced analytics and data mining? \n",
      "\n",
      "Lastly, do you have any existing data warehouse or business intelligence tools that we should consider integrating with, such as Tableau, Power BI, or Oracle OBIEE? Or would you like me to recommend some options?\n",
      "LLM: It seems like you're ready to provide more information. To further clarify your requirements, can you please tell me about the current data structures and formats used by your ERP and CRM systems? For example, are they relational databases like MySQL or PostgreSQL, or are they cloud-based systems like Salesforce or Microsoft Dynamics? \n",
      "\n",
      "Additionally, do you have any specific data governance or security requirements that need to be considered when designing the data warehouse, such as data encryption, access controls, or compliance with regulations like GDPR or HIPAA?\n",
      "\n",
      "Also, what is the expected user base for the data warehouse? Will it be used by a small team of power users, or will it be rolled out to a larger group of employees across the organization? This will help me understand the scalability and usability requirements for the data warehouse.\n",
      "\n",
      "Lastly, are there any specific key performance indicators (KPIs) or metrics that you would like to track and analyze through the data warehouse, such as customer satisfaction, sales revenue, or inventory turnover?\n",
      "LLM: It seems like you're ready to provide more information. To further clarify your requirements, can you please tell me about the desired data warehouse architecture? For example, would you like to use a traditional relational database management system like Oracle or SQL Server, or would you like to consider a more modern cloud-based data warehousing solution like Amazon Redshift, Google BigQuery, or Snowflake?\n",
      "\n",
      "Additionally, would you like to use an Extract, Transform, Load (ETL) tool like Informatica or Talend to manage the data integration process, or would you like to consider a more real-time data integration approach using tools like Apache Kafka or Apache NiFi?\n",
      "\n",
      "Also, have you considered how you would like to handle data storage and scalability for the data warehouse? For example, would you like to use a scalable storage solution like Hadoop or a cloud-based object storage like Amazon S3, or would you like to consider a more traditional storage approach using SAN or NAS storage?\n",
      "\n",
      "Lastly, are there any specific data visualization or reporting tools that you would like to use to interact with the data warehouse? For example, would you like to use a tool like Tableau or Power BI to create interactive dashboards, or would you like to consider a more custom approach using a programming language like Python or R?\n",
      "\n",
      "And one more thing, do you have a rough estimate of the project timeline and budget for the data warehouse implementation? This will help me understand the constraints and prioritize the requirements accordingly.\n",
      "LLM: It seems like you're looking to continue the conversation, but I had already gathered enough information and replied with \"STOP\" as per your initial instruction. If you'd like to discuss further or clarify any points, I'm happy to continue the conversation. What would you like to talk about?\n",
      "LLM decided to stop asking questions.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(llm=llm, memory=memory)\n",
    "\n",
    "initial_prompt = (\n",
    "    \"We need to build a data warehouse that integrates data from our ERP and CRM systems \"\n",
    "    \"to improve reporting and decision-making. Ask me any questions to clarify our requirements. \"\n",
    "    \"When you have all the information you need, simply reply with 'STOP'.\"\n",
    ")\n",
    "\n",
    "response = conversation.run(initial_prompt)\n",
    "print(\"LLM:\", response)\n",
    "\n",
    "while True:\n",
    "    # Ask the next question or prompt\n",
    "    next_output = conversation.run(\"Next question?\")\n",
    "    print(\"LLM:\", next_output)\n",
    "    \n",
    "    # Check if the LLM signals that it is done\n",
    "    if \"STOP\" in next_output.upper():\n",
    "        print(\"LLM decided to stop asking questions.\")\n",
    "        break\n",
    "\n",
    "    # (Optional) Simulate user responses here. In a real application, you might capture user input.\n",
    "    user_input = input(\"Your answer: \")\n",
    "    conversation.run(user_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
